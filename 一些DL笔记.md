# 一些DL笔记

## 基础

### 深度学习有什么作用？

特征工程是机器学习实践中最重要的一环，模型调参决定上限，但好的特征和数据能够决定下限。但是在实际问题中，想要找出优秀的特征并不是简单的事，需要耗费大量的人力，而找出特征后与其用深度学习分类不如使用可解释性更好的决策树、集成学习或者速度更快的SVM、线性判别等。而深度学习与其说是训练分类器，不如说是在寻找优质的特征。但也正因如此，DL得到的特征往往没用什么可解释性。

### 深度学习的应用领域？

一般是图像处理（CV）、音频处理等具有巨大特征数量的预测检测任务。毕竟这种原始特征巨大的任务才需要DL来寻找特征。

### 以图像识别为例，为问题建模：

#### 前向传播：计算损失

输入：**图片**

处理：**图片->像素向量** $x$

但如果每个像素点都平权考虑，背景像素就会被不理想的重视。所以给每个像素加上权重：

**像素向量->加权像素得分** $f(W,x)=Wx+b$, $b$是一个bias，微调作用。 得分最高就分为那一类。

W矩阵的每一行是每一类对于图片的权重，比如猫的权重向量（重视哪些像素）、狗的权重向量

**新问题：权重矩阵W很大，如何得到W？**

W可以通过得分和实际分类的区别来得到反馈并调整，这个区别的度量就是损失函数。

例如

​	$L_i=\Sigma_{j!=y_i} max(0, \Delta score +1)+\lambda R(W)$

其中1是一个容忍度，表示你可以容忍得分相差多少。需要精度高肯定值更高，相应的收敛困难。

$R(W)=\Sigma W_{ij}^2$是一个正则化函数，得分相同的情况可能是只考虑少数维的，也可能是平均考虑所有特征的。为了避免过拟合，需要加入正则化函数。W如果变异，损失就会变大



**R域内的分数 -> 分类概率**

Sigmoid函数：$g(x)=\frac{1}{1+e^x}$  二分类模型中用这个从实数域映射到概率分布

Softmax: $P(Y=k|X=x_i)=\frac{e^s_k}{\Sigma_j e^s_j}$   指数是为了扩大高分的差异，小分的就趋向0，最后归一化。这个计算结果是分类正确的概率值。

损失函数：$L_i=-logP$. 负对数意味着概率越接近1损失越小，越接近0损失越大。注意这个是分入每一类的损失。



#### 反向传播：调整参数

从后往前的逐层传播。利用导数的链式运算法则一步一步算。

![image-20230917154156983](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230917154156983.png)

最后导到$W$的每个元素

### 神经网络架构：前向传播+反向特征

输入层+多隐层+输出层

全连接的隐层有什么用？隐层的每一个单元都隐含了输入数据的信息。比输入层更大的隐层：扩展丰富特征数量，过拟合程度越大，精度越高，效果越好。



非线性变换：每一步矩阵计算之后，层输出之前。非线性变换用于阻断权重之间的联系，否则所有权重完全可以组合变成同一个矩阵，叠加层次就没有意义。



### 激活函数的对比：

- sigmoid：

  ![image-20230917161442880](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230917161442880.png)

  sigmoid函数作为非线性单元，在数值较大和较小时会出现梯度消失，反向传播就基本不进行更新。

- Relu：$max(0,x)$

  ![image-20230917161512778](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230917161512778.png)

  Relu没有梯度消失，主要是小于0不更新

### 数据预处理：

均值化：使得数据围绕着原点维中心

标准化：吧数据转换为合适的分布

参数初始化：随机选取初始参数，但是希望初始参数变化不大（都比较小）



### 神经网络过拟合的解决办法

1.损失函数中的正则项$R(W)$

2.DROP_OUT方法删除每层中的一部分神经元，每一次迭代杀死的神经元都不一样。测试时用全体模型。这个方法使得每一次训练的神经元减少，但整体上每个神经元都训练到了。

![image-20230917162608962](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230917162608962.png)





## CNN

### 应用领域：

图像检测、人体检测、图像分类等

图像检索：输入一个图返回相似图

超分辨率重构、无人驾驶

NN无非就是特征的提取方法，只要是特征很多难以手工操作的都可以用NN提取



### CNN和普通NN的区别：

![image-20230917163852168](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230917163852168.png)

NN输入图片把数据从三维展开到一维：28*28像素，3个颜色通道RGB全展开。

而CNN直接在三维的层面进行处理，数据保留着长宽高$h$ $w$ $c$



### CNN的结构：

输入层->卷积层->Relu->卷积->Relu->池化层->全连接层

卷积层提取特征、池化层压缩特征

CNN的层数只看带参数的层，卷积层和全连接层。

#### 卷积：数据按区域提取特征

图像识别中需要把一块一块的部位作为特征考虑，一个区域包括了多个像素点。比如一个5*5\*1的图片可以分为3\*3一组，右下角小字是权重，右边图中的值是算出的特征值.  

![image-20230917164954356](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230917164954356.png) 



具体例子：

![image-20230917170157642](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230917170157642.png)

7\*7\*3的输入图片，因为是三种颜色叠加所以每种颜色都是7*7

权重矩阵Filter（卷积核） $W_0$(是$3*3*3$)，前两个3表示原始图中多大区域提取一个特征，最后一个3表示也是三层，与输入层的三层对应。输入的小区域（**蓝色**）和W0的小区域（**红色**）对应相乘，三个区域相加，再加偏置即可得到一个特征（**绿色**区域）

使用多个Filter，就可以提取出不同的特征图。对一个图可以用多个filter得到更丰富的特征。



上述从输入到输出，就是一次卷积。



##### 卷积层堆叠：

![image-20230918121727096](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230918121727096.png)

1->2:用了6个filter，维度（32-28+1），3个矩阵（根据前图）。

2->3：10个filter，6个矩阵



多个卷积层的堆叠就是为了提取精度更高的特征。

##### CNN参数

- 步长：filter的框再输入图上的移动。

![image-20230918122133192](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230918122133192.png)

​	步长越小，特征越丰富，提取更细致。

- 卷积核尺寸：filter的大小，卷积核越大，区域越大，提取数量越小越粗糙。
- 边缘填充：+pad1意味着填充一圈。在卷积核移动的时候，有的点计算次数多，有的点计算次数少。而边界点计算次数是最少的，边界上的特征重要性就下降了。

![image-20230918122500731](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230918122500731.png)

​	解决方法就是边界加一圈0，一定弥补了边界信息缺失。

- 卷积核个数：要得到多少个特征图，前例中的filter1和filter2，最后得到两个特征图



##### 卷积结果计算公式：

![image-20230919124732925](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919124732925.png)

##### 卷积参数共享

![image-20230919125203975](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919125203975.png)

如果卷积核对每个区域都要不同的初始化参数，那么需要$75*32*32*10+10$个。

各区域卷积核一致能大大减少参数数量

#### 池化：特征的压缩

池化层做的事特征的压缩。在卷积特征的基础上做downsampling。

- maxpooling：吧特征图分为等大小区域，选出每个区域最大的值（即选出最重要的特征）。

  ![image-20230919130338784](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919130338784.png)

#### 全连接层：特征图转化为概率

特征图（$32*32*10$） 转化为向量：(10240)

全连接层大小：10240*5，得到5个特征向量

![image-20230919131206667](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919131206667.png)

### CNN经典网络：

- ALex-net

![image-20230919131341727](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919131341727.png)11*11的大卷积核，4的大步长，过分压缩的池化，没有用的标准化层。

- VGG![image-20230919131512980](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919131512980.png)

3*3的核，细粒度提取（感受野）、pooling完会把特征图数量再翻倍

- Resnet残差网络

  层数太多效果反而变差，但是直接把权重设0会导致后边连接不上。所以可以用同等映射跳过这一层.

  ![image-20230919132045301](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919132045301.png)

用了残差网络就可以放任网络增大，而不会效果下降。



### Reception Field 感受野

简单说就是卷积后的一个点受到前一层一片区域的影响，继续往前连接能感受到更大的区域。

![image-20230919132803666](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919132803666.png)

感受野越大越好，能感受到更多区域。

多个小卷积核卷积多次和一个大卷积核卷积一次的感受野一致，但小卷积核特征提取细致，参数也可能更少，Relu更多，非线性特征变化更多。



## 递归神经网络RNN

有时序的数据输入，传统神经网络不会考虑时序关系。RNN用于自然语言处理的多，因为语言具有时序联系。



![image-20230919134829348](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919134829348.png)



前一个时刻产生的特征会影响后来的特征。

结构示例：

![image-20230919135159825](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919135159825.png)

其中只有最后结果$h_t$是重要的。

输入数据x是时间有关的向量



### RNN和LSTM

RNN会记忆所有前面的输入，这使得网络的记忆能力太强了，会因为记住了一些不重要特征而导致性能下降。

LSTM：长短时记忆网络。

#### 网络单元架构：

![image-20230919135634378](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919135634378.png)

![image-20230919135700180](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919135700180.png)

上一行的输入输出是控制参数C，决定什么参数要保留，控制模型复杂度。

![image-20230919142222269](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919142222269.png)

![image-20230919135742826](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919135742826.png)

$\sigma$是sigmoid函数



## W2V

词，词袋，独热编码形成初始向量 

用神经网络做训练，目标是预测输入词的下一个词。



#### 训练数据：

构建一个滑动窗口，几个词做输入，最后的词做输出。

![image-20230919152049094](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919152049094.png)

CBOW：

![image-20230919152106087](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919152106087.png)

上下文做输入，目标词做输出。

Skipgram：

中间词做输入，四个词做输出。

​	![image-20230919152122518](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919152122518.png)

![image-20230919152337558](C:/Users/1649019876/AppData/Roaming/Typora/typora-user-images/image-20230919152337558.png)